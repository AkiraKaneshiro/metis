{
 "metadata": {
  "name": "",
  "signature": "sha256:1c7681f911e13bf47259f223ababb2b803bbdf58db7f184005c57ea294e538a6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Challenge 1\n",
      "\n",
      "Calculate the tf-idf for each word in the first 100 reviews in the nltk movie reviews corpus. For each document, print the top 10 tf-idf words."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "from nltk.tokenize import sent_tokenize\n",
      "from nltk.tokenize import TreebankWordTokenizer\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.tokenize import wordpunct_tokenize\n",
      "from nltk.tag import pos_tag\n",
      "from nltk.chunk import ne_chunk\n",
      "from textblob import TextBlob\n",
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import movie_reviews\n",
      "\n",
      "fileids = movie_reviews.fileids()[:100]\n",
      "doc_words = [movie_reviews.words(fileid) for fileid in fileids] \n",
      "documents = [' '.join(words) for words in doc_words]\n",
      "# print documents[:3]  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.util import ngrams\n",
      "from nltk.tokenize import sent_tokenize, word_tokenize\n",
      "\n",
      "from collections import Counter\n",
      "from operator import itemgetter\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "stop = stopwords.words(\"english\")\n",
      "stop += ['.', ',', '(', ')', \"'\", '\"']\n",
      "counter = Counter()\n",
      "\n",
      "for doc in documents:\n",
      "    words = TextBlob(doc).words\n",
      "    words = [w for w in words if w not in stop]\n",
      "    bigrams = ngrams(words, 2)\n",
      "    for gram in bigrams:\n",
      "        counter[gram] += 1\n",
      "counter.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[((u'special', u'effects'), 20),\n",
        " ((u'ghosts', u'mars'), 18),\n",
        " ((u'first', u'movie'), 14),\n",
        " ((u'monkey', u'bone'), 12),\n",
        " ((u'prinze', u'jr'), 12),\n",
        " ((u'even', u'though'), 11),\n",
        " ((u'hong', u'kong'), 11),\n",
        " ((u'fight', u'scenes'), 11),\n",
        " ((u'van', u'damme'), 10),\n",
        " ((u've', u'seen'), 10)]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate tf-idf\n",
      "\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer # converts str to vectors\n",
      "\n",
      "vectorizer = TfidfVectorizer(stop_words=\"english\") \n",
      "doc_vectors = vectorizer.fit_transform(documents) \n",
      "print doc_vectors\n",
      "# the tuple reflects the row (which is the document) and column (which is the feature/word), the last column is the tf-idf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 2473)\t0.0593807653591\n",
        "  (0, 7562)\t0.0647116154826\n",
        "  (0, 6788)\t0.0647116154826\n",
        "  (0, 1858)\t0.118761530718\n",
        "  (0, 8738)\t0.0526646884759\n",
        "  (0, 847)\t0.0482409217244\n",
        "  (0, 1)\t0.44936766757\n",
        "  (0, 7610)\t0.0435515399973\n",
        "  (0, 2526)\t0.0647116154826\n",
        "  (0, 5299)\t0.0526646884759\n",
        "  (0, 4224)\t0.0593807653591\n",
        "  (0, 7210)\t0.0502676168805\n",
        "  (0, 7067)\t0.0593807653591\n",
        "  (0, 7192)\t0.044936766757\n",
        "  (0, 257)\t0.0435515399973\n",
        "  (0, 8825)\t0.0295532618464\n",
        "  (0, 6075)\t0.0391277732458\n",
        "  (0, 8793)\t0.055598467004\n",
        "  (0, 4324)\t0.0365751081881\n",
        "  (0, 3774)\t0.044936766757\n",
        "  (0, 3255)\t0.0435515399973\n",
        "  (0, 555)\t0.0593807653591\n",
        "  (0, 5560)\t0.0647116154826\n",
        "  (0, 3015)\t0.0411544684019\n",
        "  (0, 7223)\t0.0593807653591\n",
        "  :\t:\n",
        "  (99, 5170)\t0.0311144588035\n",
        "  (99, 7713)\t0.0546677095664\n",
        "  (99, 4370)\t0.0633250822812\n",
        "  (99, 5692)\t0.0472432455145\n",
        "  (99, 4881)\t0.0400948510068\n",
        "  (99, 5137)\t0.0211083607604\n",
        "  (99, 3455)\t0.0360221989536\n",
        "  (99, 836)\t0.0329802950134\n",
        "  (99, 8616)\t0.0201395257058\n",
        "  (99, 180)\t0.0290040894986\n",
        "  (99, 6331)\t0.0407491235223\n",
        "  (99, 2586)\t0.0484846882083\n",
        "  (99, 4752)\t0.0427263814622\n",
        "  (99, 2943)\t0.0139100398893\n",
        "  (99, 2322)\t0.022724621602\n",
        "  (99, 4551)\t0.056199887249\n",
        "  (99, 4640)\t0.0570587258146\n",
        "  (99, 1276)\t0.0393654353237\n",
        "  (99, 591)\t0.0239360294349\n",
        "  (99, 8772)\t0.0803918209657\n",
        "  (99, 6015)\t0.0285293629073\n",
        "  (99, 4272)\t0.0162006206104\n",
        "  (99, 652)\t0.0618427568912\n",
        "  (99, 5134)\t0.0301551853736\n",
        "  (99, 5856)\t0.0203745617611\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examine the features\n",
      "\n",
      "from pprint import pprint\n",
      "vocab_index = vectorizer.vocabulary_   # vocab_index is a single dict \n",
      "\n",
      "# append all features and indices into a dict\n",
      "index_vocab = {index: feature for feature, index in vocab_index.items()}\n",
      "print 'index, word:', index_vocab.items()[:5] # examine the first 5 pairs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "index, word: [(0, u'000'), (1, u'10'), (2, u'100'), (3, u'1000'), (4, u'101')]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to iterate through doc_vectors, which is a sparse matrix, translate it to a coo matrix \n",
      "\n",
      "from scipy.sparse import coo_matrix\n",
      "\n",
      "for i in range(len(documents)):\n",
      "    individual_film = doc_vectors.getrow(i) # get the ith row as coordinate - value pairs\n",
      "    cx = coo_matrix(individual_film)\n",
      "\n",
      "    feature_tfidf = zip(cx.col, cx.data) # col is feature, data is tfidf\n",
      "    # sort by tfidf, which is cx.data, in descending order and return only the top 10\n",
      "    top_10 = sorted(feature_tfidf, key=lambda tfidf: tfidf[1], reverse=True)[:10]\n",
      "    for x in top_10:\n",
      "        print index_vocab[x[0]],x[1]\n",
      "    print\n",
      "    if i == 4: # print 5 only \n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 0.44936766757\n",
        "teen 0.174206159989\n",
        "pretty 0.154944794475\n",
        "sagemiller 0.129423230965\n",
        "memento 0.129423230965\n",
        "fuck 0.129423230965\n",
        "mind 0.120306322121\n",
        "crow 0.118761530718\n",
        "make 0.116024855091\n",
        "strangeness 0.111196934008\n",
        "\n",
        "ship 0.272020458809\n",
        "baldwin 0.272020458809\n",
        "gore 0.204473288205\n",
        "curtis 0.204473288205\n",
        "robots 0.191449222635\n",
        "sutherland 0.181346972539\n",
        "kick 0.181346972539\n",
        "crew 0.173092833203\n",
        "power 0.160068767633\n",
        "know 0.157902936396\n",
        "\n",
        "television 0.223540287165\n",
        "hair 0.187544159107\n",
        "cool 0.167655215374\n",
        "mindset 0.16095565115\n",
        "squad 0.16095565115\n",
        "mod 0.16095565115\n",
        "1960 0.16095565115\n",
        "film 0.150323634219\n",
        "nice 0.145982359748\n",
        "based 0.13943235507\n",
        "\n",
        "quest 0.30201540955\n",
        "kayley 0.263302838007\n",
        "camelot 0.263302838007\n",
        "arthur 0.169666999214\n",
        "disney 0.169666999214\n",
        "garrett 0.131651419003\n",
        "table 0.131651419003\n",
        "dragon 0.12080616382\n",
        "animation 0.12080616382\n",
        "personality 0.113111332809\n",
        "\n",
        "stalked 0.531999460759\n",
        "daryl 0.310333018776\n",
        "brooke 0.26599973038\n",
        "stalker 0.26599973038\n",
        "psycho 0.122043526942\n",
        "door 0.108240173195\n",
        "house 0.107224203425\n",
        "ex 0.0991481365149\n",
        "toolbox 0.0886665767932\n",
        "ditzy 0.0886665767932\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Challenge 2\n",
      "\n",
      "Create a mongo collection of tweets about something (Using the twitter API, make a search and get at least 500 tweets). Each mongo document should contain the text, username, favorite count and retweet count of the tweet.\n",
      "\n",
      "Calculate the tf-idf for each word in the tweets you uploaded to your mongodb. For each tweet, print the highest tf-idf term. What are potential problems when trying to calculate tf-idf on really short documents like tweets?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymongo\n",
      "\n",
      "c = pymongo.MongoClient()\n",
      "db = c['chocolatedb']\n",
      "tweets = db['tweets']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "access_token = \"\"\n",
      "access_secret = \"\"\n",
      "consumer_key = \"\"\n",
      "consumer_secret = \"\"\n",
      "\n",
      "import tweepy\n",
      "\n",
      "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "auth.set_access_token(access_token, access_secret)\n",
      "\n",
      "api = tweepy.API(auth)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Query 500 tweets on chocolate\n",
      "\n",
      "query = \"chocolate\"\n",
      "max_tweets = 500\n",
      "\n",
      "search_results = tweepy.Cursor(api.search, q=query).items(max_tweets)\n",
      "for i, tweet in enumerate(search_results):\n",
      "    # username is within user dict \n",
      "    doc = {'text': tweet.text, 'username': tweet.user.screen_name, 'favorites': tweet.favorite_count, 'retweets': tweet.retweet_count }\n",
      "    tweets.save(doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweets.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "500"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examine one tweet that has a favorites greater than or equal to two\n",
      "from pprint import pprint\n",
      "tweet = tweets.find_one({\"favorites\": {\"$gte\": 2}})\n",
      "pprint(tweet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'_id': ObjectId('54ef87d82f63993456e588c1'),\n",
        " u'favorites': 2,\n",
        " u'retweets': 2,\n",
        " u'text': u'Turn your avocados and dates into this raw chocolate lime pie! http://t.co/ZKV4QLASrU #fdbloggers #raw #superfoods http://t.co/yL4KQXpIzH',\n",
        " u'username': u'WholeIngredient'}\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examine how TextBlob parses tweets \n",
      "TextBlob(tweet['text']).words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "WordList([u'Turn', u'your', u'avocados', u'and', u'dates', u'into', u'this', u'raw', u'chocolate', u'lime', u'pie', u'http', u't.co/ZKV4QLASrU', u'fdbloggers', u'raw', u'superfoods', u'http', u't.co/yL4KQXpIzH'])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examine the sentiment of the tweet\n",
      "TextBlob(tweet['text']).sentiment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "Sentiment(polarity=-0.25961538461538464, subjectivity=0.46153846153846156)"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save tweet text\n",
      "\n",
      "import re\n",
      "\n",
      "all_text = \"\"\n",
      "tweet_list = []\n",
      "for tweet in tweets.find():\n",
      "    text = tweet['text'].lower()\n",
      "    text = re.sub('@\\S+', ' ', text)  # Remove mentions\n",
      "    text = re.sub('http\\S+', ' ', text)  # Remove urls\n",
      "    tweet_list.append(text) # TfidfVectorizer requires a list\n",
      "    all_text += text + \"\\n\" # TextBlob requires str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(tweet_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "500"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examine one parsed tweet\n",
      "print tweet_list[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'cadeaux', u'bonprix', u'hershey', u'silver', u'plush', u'stuffed', u'toy', u'chocolate', u'kiss']\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examine the top 20 parsed words, unfiltered\n",
      "for word, count in sorted(TextBlob(all_text).word_counts.items(), key=lambda item: item[1], reverse=True)[:20]:\n",
      "    print \"%15s %i\" % (word, count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "      chocolate 488\n",
        "             rt 279\n",
        "              a 95\n",
        "            the 90\n",
        "            and 78\n",
        "              i 63\n",
        "             de 56\n",
        "           chip 53\n",
        "             to 51\n",
        "        cookies 48\n",
        "         double 44\n",
        "            hot 43\n",
        "             at 40\n",
        "            for 39\n",
        "             my 38\n",
        "             me 37\n",
        "             of 36\n",
        "             in 34\n",
        "           cake 32\n",
        "             is 31\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  filter out stop words\n",
      "from nltk.corpus import stopwords\n",
      "stop = stopwords.words('english')\n",
      "stop += [\"chocolate\", \"rt\"] # Add these words to the stop words\n",
      "\n",
      "for word, count in sorted(TextBlob(all_text).word_counts.items(), key=lambda item: item[1], reverse=True)[:50]:\n",
      "    if word not in stop:\n",
      "        print \"%15s %i\" % (word, count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             de 56\n",
        "           chip 53\n",
        "        cookies 48\n",
        "         double 44\n",
        "            hot 43\n",
        "           cake 32\n",
        "            que 25\n",
        "            n't 23\n",
        "             el 20\n",
        "              y 20\n",
        "            amp 20\n",
        "            bar 19\n",
        "          cream 19\n",
        "          pizza 18\n",
        "             \ud83d\ude02 16\n",
        "        someone 16\n",
        "             la 16\n",
        "           warm 15\n",
        "            con 15\n",
        "            old 15\n",
        "          chewy 15\n",
        "           dark 15\n",
        "             un 15\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# vectorize tweets to calculate tf-idf\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer \n",
      "\n",
      "stop = stopwords.words('english')\n",
      "stop += [\"chocolate\", \"rt\"]\n",
      "         \n",
      "vectorizer = TfidfVectorizer(stop_words=stop)\n",
      "# print tweet_list[0]\n",
      "\n",
      "tweet_vectors = vectorizer.fit_transform(tweet_list) \n",
      "print tweet_vectors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 710)\t0.365155789143\n",
        "  (0, 1265)\t0.365155789143\n",
        "  (0, 1189)\t0.287556862318\n",
        "  (0, 978)\t0.365155789143\n",
        "  (0, 1140)\t0.365155789143\n",
        "  (0, 632)\t0.342459557999\n",
        "  (0, 136)\t0.365155789143\n",
        "  (0, 176)\t0.365155789143\n",
        "  (1, 273)\t0.52019474089\n",
        "  (1, 222)\t0.501880033385\n",
        "  (1, 218)\t0.691023779359\n",
        "  (2, 1205)\t0.279471203235\n",
        "  (2, 927)\t0.279471203235\n",
        "  (2, 217)\t0.279471203235\n",
        "  (2, 529)\t0.256136584715\n",
        "  (2, 556)\t0.279471203235\n",
        "  (2, 118)\t0.558942406469\n",
        "  (2, 322)\t0.266329827581\n",
        "  (2, 310)\t0.203003618856\n",
        "  (2, 747)\t0.203003618856\n",
        "  (2, 1332)\t0.279471203235\n",
        "  (2, 612)\t0.279471203235\n",
        "  (3, 27)\t0.637048263532\n",
        "  (3, 347)\t0.637048263532\n",
        "  (3, 310)\t0.433980437187\n",
        "  :\t:\n",
        "  (495, 845)\t0.312356201315\n",
        "  (495, 889)\t0.292941724658\n",
        "  (495, 1239)\t0.279166934254\n",
        "  (495, 1307)\t0.292941724658\n",
        "  (495, 1208)\t0.259752457598\n",
        "  (496, 1346)\t0.691023779359\n",
        "  (496, 273)\t0.52019474089\n",
        "  (496, 222)\t0.501880033385\n",
        "  (497, 1179)\t0.295846763197\n",
        "  (497, 134)\t0.295846763197\n",
        "  (497, 1284)\t0.295846763197\n",
        "  (497, 99)\t0.290504663378\n",
        "  (497, 350)\t0.290504663378\n",
        "  (497, 1367)\t0.295846763197\n",
        "  (497, 104)\t0.295846763197\n",
        "  (497, 1134)\t0.290504663378\n",
        "  (497, 358)\t0.290504663378\n",
        "  (497, 1184)\t0.285590407921\n",
        "  (497, 970)\t0.262291484153\n",
        "  (497, 1158)\t0.272842302428\n",
        "  (498, 665)\t0.601139069082\n",
        "  (498, 445)\t0.601139069082\n",
        "  (498, 91)\t0.526558296152\n",
        "  (499, 365)\t0.553033658286\n",
        "  (499, 159)\t0.833158912094\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# examine the features\n",
      "\n",
      "from pprint import pprint\n",
      "vocab_index = vectorizer.vocabulary_   # vocab_index is a single dict \n",
      "\n",
      "# append all features and indices into a dict\n",
      "index_vocab = {index: feature for feature, index in vocab_index.items()}\n",
      "print 'index, word:', index_vocab.items()[:5] # examine the first 5 pairs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "index, word: [(0, u'100'), (1, u'11'), (2, u'11am'), (3, u'12'), (4, u'150226')]\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# to iterate through tweet_vectors, which is a sparse matrix, translate it to a coo matrix \n",
      "\n",
      "from scipy.sparse import coo_matrix\n",
      "from pprint import pprint\n",
      "\n",
      "top_tweet_list = []\n",
      "\n",
      "for i in range(len(tweet_list)):\n",
      "    individual_tweet = tweet_vectors.getrow(i) # get the ith row as coordinate - value pairs\n",
      "    cx = coo_matrix(individual_tweet)\n",
      "\n",
      "    feature_tfidf = zip(cx.col, cx.data) # col is feature, data is tfidf\n",
      "    # sort by tfidf, which is cx.data, in descending order and return only the top one\n",
      "    top_1 = sorted(feature_tfidf, key=lambda tfidf: tfidf[1], reverse=True)[:1]\n",
      "\n",
      "    for x in top_1:         \n",
      "        top_tweet_list.append([index_vocab[x[0]],x[1]])\n",
      "pprint(sorted(top_tweet_list, key=lambda tfidf: tfidf[1], reverse=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[u'necesito', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'delight', 1.0],\n",
        " [u'eaten', 1.0],\n",
        " [u'centaurotesticulo', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'cake', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'cake', 1.0],\n",
        " [u'waffles', 1.0],\n",
        " [u'chip', 1.0],\n",
        " [u'llorando', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'good', 1.0],\n",
        " [u'quero', 1.0],\n",
        " [u'cake', 1.0],\n",
        " [u'cake', 1.0],\n",
        " [u'1975', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'1975', 1.0],\n",
        " [u'rain', 1.0],\n",
        " [u'looooooooooooooooool', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'sprinkles', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'mmmmmm', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'cake', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'cupcakes', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'souffle', 1.0],\n",
        " [u'delicioso', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'stunning', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'cake', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'cake', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'double', 1.0],\n",
        " [u'quiero', 1.0],\n",
        " [u'lasagna', 1.0],\n",
        " [u'cake', 1.0],\n",
        " [u'milk', 1.0],\n",
        " [u'nah', 1.0],\n",
        " [u'fault', 1.0],\n",
        " [u'cake', 1.0],\n",
        " [u'love', 1.0],\n",
        " [u'gt', 0.89035953223359232],\n",
        " [u'gross', 0.88622802510688947],\n",
        " [u'donut', 0.88236651037880742],\n",
        " [u'bizcochitos', 0.88236651037880742],\n",
        " [u'pancakes', 0.8748850657098779],\n",
        " [u'lava', 0.86867831697732723],\n",
        " [u'cups', 0.84973350526302438],\n",
        " [u'cups', 0.84973350526302438],\n",
        " [u'cups', 0.84973350526302438],\n",
        " [u'cups', 0.84973350526302438],\n",
        " [u'marshmallow', 0.83328377203216275],\n",
        " [u'marshmallow', 0.83328377203216275],\n",
        " [u'brownies', 0.83315891209449888],\n",
        " [u'want', 0.81616769368957431],\n",
        " [u'amo', 0.80306380686547951],\n",
        " [u'tease', 0.78563978835100612],\n",
        " [u'life', 0.78370498038845438],\n",
        " [u'life', 0.78370498038845438],\n",
        " [u'lebanon', 0.77783926793904412],\n",
        " [u'cheesecake', 0.77080811744914024],\n",
        " [u'cheesecake', 0.77080811744914024],\n",
        " [u'cheesecake', 0.77080811744914024],\n",
        " [u'goodbye', 0.76887989380956523],\n",
        " [u'amp', 0.76851682139190902],\n",
        " [u'mint', 0.75934584044214459],\n",
        " [u'covered', 0.75913294344441251],\n",
        " [u'gg', 0.75835795392863736],\n",
        " [u'cake', 0.75533357330559747],\n",
        " [u'dip', 0.75029914675420817],\n",
        " [u'cream', 0.75020824944083075],\n",
        " [u'cream', 0.75020824944083075],\n",
        " [u'cream', 0.75020824944083075],\n",
        " [u'cream', 0.75020824944083075],\n",
        " [u'cream', 0.75020824944083075],\n",
        " [u'needitnow', 0.74560852056492122],\n",
        " [u'donuts', 0.74181094297021266],\n",
        " [u'donuts', 0.74181094297021266],\n",
        " [u'sim', 0.73921227924362432],\n",
        " [u'strawberry', 0.73606796234531457],\n",
        " [u'strawberry', 0.73606796234531457],\n",
        " [u'energy', 0.73138682484680451],\n",
        " [u'biscotti', 0.72941160308585651],\n",
        " [u'sandwiches', 0.72593511153904711],\n",
        " [u'foodporn', 0.72392214900992702],\n",
        " [u'hot', 0.72080471576704896],\n",
        " [u'cookies', 0.71966200016254478],\n",
        " [u'cookies', 0.71966200016254478],\n",
        " [u'puppy', 0.70710678118654757],\n",
        " [u'jajajaja', 0.70710678118654757],\n",
        " [u'puppy', 0.70710678118654757],\n",
        " [u'qr', 0.70710678118654746],\n",
        " [u'grupo', 0.70710678118654746],\n",
        " [u'required', 0.70710678118654746],\n",
        " [u'mas', 0.70710678118654746],\n",
        " [u'boojabooja', 0.70710678118654746],\n",
        " [u'sandwich', 0.699934149738208],\n",
        " [u'fudge', 0.69954818368985161],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'chewy', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'warm', 0.69102377935901127],\n",
        " [u'layer', 0.69070507745032805],\n",
        " [u'drink', 0.6851147222833287],\n",
        " [u'banana', 0.67627980022031198],\n",
        " [u'\\u30b8\\u30e0\\u3067\\u30a8\\u30af\\u30b5\\u30b5\\u30a4\\u30ba\\u4e2d',\n",
        "  0.66666666666666674],\n",
        " [u'actually', 0.66534019768195696],\n",
        " [u'soft', 0.66191904830646042],\n",
        " [u'rn', 0.65848708745202245],\n",
        " [u'sorvetes', 0.6581742394602681],\n",
        " [u'florida', 0.65775639417213505],\n",
        " [u'brownies', 0.65771012770246129],\n",
        " [u'quiero', 0.65639396607227662],\n",
        " [u'pan', 0.65579736743159855],\n",
        " [u'rainybot', 0.65321310173058356],\n",
        " [u'\\u03b1\\u2113', 0.65321310173058356],\n",
        " [u'balls', 0.64989687668185692],\n",
        " [u'disgusting', 0.64989687668185692],\n",
        " [u'malteada', 0.6497576514186395],\n",
        " [u'relationships', 0.64673636267827328],\n",
        " [u'toasted', 0.64662881952066953],\n",
        " [u're', 0.64405417596464254],\n",
        " [u'salad', 0.64164755841381804],\n",
        " [u'looks', 0.64145406410057104],\n",
        " [u'pretzels', 0.64131742169399997],\n",
        " [u'wait', 0.63926924393005657],\n",
        " [u'crave', 0.63926924393005657],\n",
        " [u'bruh', 0.63867055397818639],\n",
        " [u'votelittlemixuk', 0.63843747673543971],\n",
        " [u'sandwich', 0.6376591246865978],\n",
        " [u'addictive', 0.63704826353229094],\n",
        " [u'addiction', 0.63530039879315825],\n",
        " [u'gooey', 0.63147242253497748],\n",
        " [u'fairtrade', 0.6179954064311759],\n",
        " [u'pastry', 0.61722235535464842],\n",
        " [u'sorcery', 0.61397085469397217],\n",
        " [u'preparar', 0.61227786014015861],\n",
        " [u'walk', 0.61103713850804875],\n",
        " [u'rather', 0.61103713850804875],\n",
        " [u'estre\\xf1io', 0.61103713850804875],\n",
        " [u'laughed', 0.60953599158944838],\n",
        " [u'wanna', 0.60912190034906388],\n",
        " [u'jajaj', 0.60692448555354161],\n",
        " [u'dip', 0.60396009208223078],\n",
        " [u'guard', 0.60202669205983228],\n",
        " [u'illusion', 0.60113906908180559],\n",
        " [u'illusion', 0.60113906908180559],\n",
        " [u'illusion', 0.60113906908180559],\n",
        " [u'illusion', 0.60113906908180559],\n",
        " [u'illusion', 0.60113906908180559],\n",
        " [u'illusion', 0.60113906908180559],\n",
        " [u'illusion', 0.60113906908180559],\n",
        " [u'illusion', 0.60113906908180559],\n",
        " [u'illusion', 0.60113906908180559],\n",
        " [u'illusion', 0.60113906908180559],\n",
        " [u'women', 0.59690477790834562],\n",
        " [u'oreo', 0.59561498859594786],\n",
        " [u'oreo', 0.59561498859594786],\n",
        " [u'oreo', 0.59561498859594786],\n",
        " [u'oreo', 0.59561498859594786],\n",
        " [u'iced', 0.59251733447322019],\n",
        " [u'suspendaowhatsapps\\xf3dequem', 0.5895044370173127],\n",
        " [u'dick', 0.58930134588182082],\n",
        " [u'someone', 0.58664523651624334],\n",
        " [u'lovren', 0.58639514368786516],\n",
        " [u'pound', 0.585526458964995],\n",
        " [u'incredible', 0.58304349962786528],\n",
        " [u'amazing', 0.57999220768489457],\n",
        " [u'tell', 0.57900829656560959],\n",
        " [u'doughnuts', 0.57791396327798472],\n",
        " [u'doughnuts', 0.57791396327798472],\n",
        " [u'doughnuts', 0.57791396327798472],\n",
        " [u'doughnuts', 0.57791396327798472],\n",
        " [u'doughnuts', 0.57791396327798472],\n",
        " [u'doughnuts', 0.57791396327798472],\n",
        " [u'gwey', 0.57735026918962573],\n",
        " [u'vaini_chocolate', 0.57735026918962573],\n",
        " [u'flakes', 0.57735026918962573],\n",
        " [u'try', 0.57128780723729111],\n",
        " [u'af', 0.56950841603001723],\n",
        " [u'mmmmmmmmdespues', 0.56872126800889922],\n",
        " [u'raw', 0.56315542521885575],\n",
        " [u'evans', 0.56219195039174763],\n",
        " [u'hunger', 0.56041431842069278],\n",
        " [u'sweets', 0.56010802356265688],\n",
        " [u'hahaha', 0.55978388941173451],\n",
        " [u'bittersweet', 0.55894240646913884],\n",
        " [u'bittersweet', 0.55894240646913884],\n",
        " [u'hmm', 0.55700239719058087],\n",
        " [u'brownies', 0.5552882084349644],\n",
        " [u'brownies', 0.5552882084349644],\n",
        " [u'oatmeal', 0.55097635666125111],\n",
        " [u'estou', 0.54758143150861849],\n",
        " [u'frappachino', 0.54687803522245526],\n",
        " [u'pacquiao', 0.54685092913648337],\n",
        " [u'said', 0.54563003284401512],\n",
        " [u'blend', 0.5382585995739787],\n",
        " [u'imediata', 0.53526290248122266],\n",
        " [u'love', 0.53512931557094701],\n",
        " [u'vote5sos', 0.53255815767480175],\n",
        " [u'heehee', 0.53015624571356557],\n",
        " [u'ain', 0.52944616128197186],\n",
        " [u'gods', 0.52917488750217978],\n",
        " [u'regret', 0.52646103095425945],\n",
        " [u'carrageenmoss', 0.52322328145992492],\n",
        " [u'shall', 0.52311716082974224],\n",
        " [u'fundido', 0.52149924942307269],\n",
        " [u'brought', 0.51728769324300095],\n",
        " [u'crazy', 0.51347068631420101],\n",
        " [u'swearing', 0.51171789074301144],\n",
        " [u'new', 0.5099778914919787],\n",
        " [u'door', 0.509908749936686],\n",
        " [u'feliz', 0.50770230361484969],\n",
        " [u'foodporn', 0.50627643191149085],\n",
        " [u'hizo', 0.50622971070048828],\n",
        " [u'yakult', 0.50234519379253739],\n",
        " [u'mordida', 0.50201595463085347],\n",
        " [u'btw', 0.5],\n",
        " [u'auditionssucksometimes', 0.49889360914083597],\n",
        " [u'auditionssucksometimes', 0.49889360914083597],\n",
        " [u'gelati', 0.49585627631572105],\n",
        " [u'el', 0.49334885972817788],\n",
        " [u'italian', 0.49317276869138427],\n",
        " [u'de', 0.49221777861355248],\n",
        " [u'cara', 0.49052170475768542],\n",
        " [u'burgers', 0.48919262973478894],\n",
        " [u'forgot', 0.48917964654756313],\n",
        " [u'spray', 0.48864910033409603],\n",
        " [u'fudge', 0.48864685145511028],\n",
        " [u'love', 0.48817376471845125],\n",
        " [u'cakeoftheday', 0.48518133269967878],\n",
        " [u'meal', 0.48510375314904702],\n",
        " [u'apetece', 0.48505060775299685],\n",
        " [u'un', 0.48406254263918702],\n",
        " [u'ducks', 0.48376730234706455],\n",
        " [u'caf\\xe9', 0.47981439187599845],\n",
        " [u'pacquiao', 0.47979608464700912],\n",
        " [u'emojis', 0.47906624964295136],\n",
        " [u'pullovers', 0.47528483684707445],\n",
        " [u'voteluansanana', 0.47471581488714898],\n",
        " [u'swirled', 0.47349566974223478],\n",
        " [u'swirled', 0.47349566974223478],\n",
        " [u'mail', 0.47329199132420324],\n",
        " [u'gave', 0.47285703292211007],\n",
        " [u'beans', 0.47191216575869172],\n",
        " [u'brigadeiros', 0.47119158958764129],\n",
        " [u'nada', 0.46665678823929019],\n",
        " [u'something', 0.46523820386674875],\n",
        " [u'fil', 0.46233244651285704],\n",
        " [u'normal', 0.46233244651285704],\n",
        " [u'week', 0.46004874815834929],\n",
        " [u'lately', 0.45955501379513541],\n",
        " [u'boys', 0.45841301834928083],\n",
        " [u'key', 0.458392260210988],\n",
        " [u'rellos', 0.45709094936596634],\n",
        " [u'rellos', 0.45709094936596634],\n",
        " [u'cupcakes', 0.45456019120359414],\n",
        " [u'dough', 0.45436133622911568],\n",
        " [u'dough', 0.45436133622911568],\n",
        " [u'images', 0.45269944621533953],\n",
        " [u'ti', 0.45122964955047884],\n",
        " [u'parody', 0.4473205365961947],\n",
        " [u'de', 0.44577602698427349],\n",
        " [u'traer', 0.44317702299728395],\n",
        " [u'de', 0.44227060877722291],\n",
        " [u'freses', 0.44144308934818594],\n",
        " [u'enchendo', 0.44005669809662795],\n",
        " [u'cheesecakes', 0.43920259220222357],\n",
        " [u'winefestival', 0.43533495955503537],\n",
        " [u'winefestival', 0.43533495955503537],\n",
        " [u'bus', 0.43501271892496646],\n",
        " [u'favor', 0.43414295480500814],\n",
        " [u'tramp', 0.43327518592543807],\n",
        " [u'delicious', 0.43187540375208017],\n",
        " [u'mains', 0.42813622685211294],\n",
        " [u'mains', 0.42813622685211294],\n",
        " [u'de', 0.42689555719722649],\n",
        " [u'look', 0.42526498441173877],\n",
        " [u'que', 0.42522138869684234],\n",
        " [u'suggestion', 0.42473252963568009],\n",
        " [u'negative', 0.42453210962778565],\n",
        " [u'soft', 0.42213978741171737],\n",
        " [u'viagra', 0.4218860678701879],\n",
        " [u'es', 0.41995288620608945],\n",
        " [u'v\\xeda', 0.41415610195469044],\n",
        " [u'paladar', 0.41255336784645902],\n",
        " [u'ferry', 0.41208737887454233],\n",
        " [u'buttered', 0.41138633525451618],\n",
        " [u'selftreat', 0.41075091793027591],\n",
        " [u'selftreat', 0.41075091793027591],\n",
        " [u'haahaa', 0.40974535623318825],\n",
        " [u'\\u3053\\u308c\\u3092\\u898b\\u305f\\u4eba\\u306f\\u6c17\\u3092\\u3064\\u3051\\u307e\\u3057\\u3087\\u3046\\uff57',\n",
        "  0.40824829046386302],\n",
        " [u'later', 0.40726757411513792],\n",
        " [u'un', 0.40526597293420547],\n",
        " [u'ingredients', 0.40502027997623941],\n",
        " [u'ecstasy', 0.40389899203378576],\n",
        " [u'pocket', 0.40342023102892144],\n",
        " [u'olvides', 0.40257263722761266],\n",
        " [u'juniormints', 0.40207041088790746],\n",
        " [u'gets', 0.39971863091463761],\n",
        " [u'grandmas', 0.39851407442287928],\n",
        " [u'chocolatefeet', 0.39845772624232983],\n",
        " [u'watching', 0.39819757900335051],\n",
        " [u'de', 0.39733340578082837],\n",
        " [u'pazocoruxo', 0.39621824759543373],\n",
        " [u'indeed', 0.3955687514110714],\n",
        " [u'watches', 0.39435076116803797],\n",
        " [u'sweetened', 0.3920283575889541],\n",
        " [u'le', 0.39109504449420301],\n",
        " [u'cravings', 0.39056643041138289],\n",
        " [u'palmera', 0.39007174409078238],\n",
        " [u'palmera', 0.39007174409078238],\n",
        " [u'palmera', 0.39007174409078238],\n",
        " [u'palmera', 0.39007174409078238],\n",
        " [u'partnership', 0.38770175790272543],\n",
        " [u'lo', 0.38716298909249419],\n",
        " [u'smart', 0.3822954927513259],\n",
        " [u'colombia', 0.38223684998853585],\n",
        " [u'colombia', 0.38223684998853585],\n",
        " [u'colombia', 0.38223684998853585],\n",
        " [u'colombia', 0.38223684998853585],\n",
        " [u'eatbetter', 0.38125880080762375],\n",
        " [u'hamantaschen', 0.38125880080762375],\n",
        " [u'bd9', 0.3812588008076237],\n",
        " [u'stepped', 0.38098163484633218],\n",
        " [u'por', 0.38049060495931253],\n",
        " [u'que', 0.37798724076092222],\n",
        " [u'buying', 0.37769442477129139],\n",
        " [u'sick', 0.37701080740849929],\n",
        " [u'easteregg', 0.37615402387341046],\n",
        " [u'feira', 0.37374204434511848],\n",
        " [u'promo', 0.37147784721675031],\n",
        " [u'probablytired', 0.37020041150422028],\n",
        " [u'hoping', 0.36938010609269389],\n",
        " [u'ingleses', 0.36853251320521407],\n",
        " [u'ingleses', 0.36853251320521407],\n",
        " [u'ftw', 0.36790935974792449],\n",
        " [u'boldandbeautiful', 0.36602586090333711],\n",
        " [u'kiss', 0.36515578914323749],\n",
        " [u'comeondontbeshy', 0.36374730370724351],\n",
        " [u'eidoprosmoothie', 0.36320669353781893],\n",
        " [u'useful', 0.36181903075791988],\n",
        " [u'truffle', 0.36148461792976427],\n",
        " [u'electricarea', 0.35899974171009164],\n",
        " [u'yummy', 0.35808542082364619],\n",
        " [u'un', 0.35696731480872956],\n",
        " [u'waterrrrrrrrrr', 0.35647118658020704],\n",
        " [u'hour', 0.35556309224290755],\n",
        " [u'healthiest', 0.35467471414359819],\n",
        " [u'collection', 0.35356685708507657],\n",
        " [u'oops', 0.35336489278124583],\n",
        " [u'nash', 0.35000159618713983],\n",
        " [u'shut', 0.34873153874429091],\n",
        " [u'gorda', 0.34859648648766678],\n",
        " [u'spotify', 0.34759873307443262],\n",
        " [u'2012', 0.34647524366302729],\n",
        " [u'pracaramba', 0.34592616273090077],\n",
        " [u'de', 0.34445179410043458],\n",
        " [u'hbgsmc', 0.34244801012634546],\n",
        " [u'insane', 0.34150120909892634],\n",
        " [u'support', 0.340186476715788],\n",
        " [u'laamo', 0.33745352185651306],\n",
        " [u'fall', 0.33580637565343097],\n",
        " [u'de', 0.33456380008187209],\n",
        " [u'smile', 0.33298474446735771],\n",
        " [u'croissant', 0.33287467423183881],\n",
        " [u'que', 0.33194312825312572],\n",
        " [u'pomade', 0.33155175271623383],\n",
        " [u'secrets', 0.32832904510795624],\n",
        " [u'edible', 0.32736540491195992],\n",
        " [u'crisps', 0.32269276530190216],\n",
        " [u'fine', 0.3221006981881131],\n",
        " [u'ignore', 0.3220324671643312],\n",
        " [u'arriba', 0.32196038616251849],\n",
        " [u'que', 0.32116356063875712],\n",
        " [u'de', 0.31959676151219196],\n",
        " [u'rebel', 0.31950161008725847],\n",
        " [u'fields', 0.31711453630756109],\n",
        " [u'impune', 0.31706938970555593],\n",
        " [u'random', 0.316227766016838],\n",
        " [u'kind', 0.31563990149804427],\n",
        " [u'chocolatelovers', 0.31496519340004175],\n",
        " [u'8217', 0.31326006908679793],\n",
        " [u'canned', 0.31274773490295882],\n",
        " [u'canned', 0.31274773490295882],\n",
        " [u'canned', 0.31274773490295882],\n",
        " [u'toothpaste', 0.31235620131500763],\n",
        " [u'febreroconsabor', 0.31069627843230391],\n",
        " [u'henrydanger', 0.30748636846024607],\n",
        " [u'kprs', 0.30608984201085654],\n",
        " [u'kprs', 0.30608984201085654],\n",
        " [u'kprs', 0.30608984201085654],\n",
        " [u'kprs', 0.30608984201085654],\n",
        " [u'ht', 0.30566139224173688],\n",
        " [u'education', 0.30500954267839275],\n",
        " [u'dogs', 0.30486803491088293],\n",
        " [u'jajajajnanana', 0.30417951628831918],\n",
        " [u'de', 0.30234334665006263],\n",
        " [u'secret', 0.30153160601110945],\n",
        " [u'ricans', 0.30118249143498532],\n",
        " [u'frita', 0.29678452468438199],\n",
        " [u'frita', 0.29678452468438199],\n",
        " [u'frita', 0.29678452468438199],\n",
        " [u'frita', 0.29678452468438199],\n",
        " [u'frita', 0.29678452468438199],\n",
        " [u'snoozies', 0.29599152008202978],\n",
        " [u'step', 0.29584676319730024],\n",
        " [u'step', 0.29584676319730024],\n",
        " [u'step', 0.29584676319730024],\n",
        " [u'step', 0.29584676319730024],\n",
        " [u'step', 0.29584676319730024],\n",
        " [u'step', 0.29584676319730024],\n",
        " [u'step', 0.29584676319730024],\n",
        " [u'step', 0.29584676319730024],\n",
        " [u'step', 0.29584676319730024],\n",
        " [u'step', 0.29584676319730024],\n",
        " [u'right', 0.29250640797794536],\n",
        " [u'ou', 0.29168646971985057],\n",
        " [u'insomnia', 0.29139518742314507],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'syria', 0.28463644478512834],\n",
        " [u'motherhood', 0.28162269490529612],\n",
        " [u'salida', 0.27925992715337927],\n",
        " [u'cocteler\\xeda', 0.27648261383724548],\n",
        " [u'prefiro', 0.27422200515625222],\n",
        " [u'able', 0.26946257242748511],\n",
        " [u'preis', 0.25819888974716115],\n",
        " [u'dele', 0.24774234354359537],\n",
        " [u'de', 0.24629604050547813]]\n"
       ]
      }
     ],
     "prompt_number": 79
    }
   ],
   "metadata": {}
  }
 ]
}